LoRA - LoRA is low-rank decomposition method to reduce the number of trainable parameters which speeds up finetuning...
> https://huggingface.co/docs/peft/main/developer_guides/lora

Fine-Tune Gemma 3: A Step-by-Step Guide With Financial Q&A Dataset
> https://www.datacamp.com/tutorial/fine-tune-gemma-3
 
Fine-tuning Llama 3.2 and Using It Locally: A Step-by-Step Guide
> https://www.datacamp.com/tutorial/fine-tuning-llama-3-2

GPT FineTuning
> https://platform.openai.com/docs/guides/model-optimization

Fine-tuning on Hugging Face
> https://huggingface.co/docs/transformers/en/training

 